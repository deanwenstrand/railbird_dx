type: action
name: data_analytics
description: "Answer analytical questions about your data with smart visualizations"
version: 1.0
completion_behavior: auto_final

# LLM Integration - perfect for natural language analytics
ai:
  when_to_use: "When user asks analytical questions about data, counts, trends, breakdowns, or statistics"
  examples:
    - "how many contacts were created last month?"
    - "show me opportunities by stage"
    - "count accounts by industry" 
    - "contacts from technology companies created this year"
    - "breakdown of activities by type"
    - "how many leads came in yesterday?"
    - "opportunities over $10k in proposing stage"
  effect: read
  priority: high
  tags: ["analytics", "data", "query", "visualization", "reporting"]

# Multi-step DSL with inline AI prompts
implementation:
  type: dsl_logic
  logic:
    steps:
      # Phase 0: Fast Path - Try simple pattern matching first
      - action: python
        code: |
          from core.nlp.fast_patterns import FastQueryPattern
          
          fast_matcher = FastQueryPattern()
          fast_spec = fast_matcher.try_fast_match(input.query)
          
          result = {
              'spec': fast_spec,
              'matched': fast_spec is not None,
              'pattern_type': fast_spec.get('_llm_meta', {}).get('fast_path') if fast_spec else None
          }
          
          # Log fast path matching with structured logging
          from core.logging.setup import get_logger
          logger = get_logger('ai.data_analytics')
          logger.debug(f"Fast path matching for query: {input.query}", extra={
              'step': 0, 'query': input.query, 'fast_spec': str(fast_spec), 
              'matched': result['matched'], 'pattern_type': result.get('pattern_type')
          })
        store_as: fast_path_result
      
      # Phase 1: Schema Introspection - Get available objects from live DB (skip if fast path matched)
      - action: python
        condition: "not {fast_path_result.matched}"
        code: |
          from core.query_builder.introspection import get_available_schema_objects
          result = get_available_schema_objects()
          result['_metadata'] = {
              'phase': 'schema_introspection', 
              'generated_at': 'now'
          }
        store_as: available_objects

      # Phase 2: Precompute Time Candidates (fast, deterministic) - always needed for validator
      - action: python
        code: |
          from core.nlp.time_ranges import build_time_candidates
          result = build_time_candidates(tz="America/Los_Angeles")
        store_as: time_candidates

      # Phase 3: Enhanced Intent Analysis & Schema Discovery (skip if fast path matched)
      - action: ai_generate
        condition: "not {fast_path_result.matched}"
        model: "gpt-4o-mini"  # Fast pattern recognition - cheap & low latency
        temperature: 0.1
        max_tokens: 800
        context:
          user_query: "{input.query}"
          available_objects: "{available_objects}"
          time_candidates: "{time_candidates.candidates}"
        system_prompt: |
          role: CRM_ANALYTICS_INTENT_ANALYZER
          domain: ["sales_data", "marketing_data", "customer_data"]
          intent: "Parse natural language queries into structured analytics intent"

          user_query: "{user_query}"
          available_objects: "{available_objects}"

          object_mappings:
            deals: ["deals", "deal", "opportunities", "opportunity", "pipeline", "sales"] → "opportunity"
            contacts: ["contacts", "contact", "leads", "prospects", "people", "users"] → "contact"  
            accounts: ["accounts", "account", "companies", "clients", "customers"] → "account"

          terminology_map:
            revenue_queries: ["revenue", "amount", "value", "worth", "total", "sum"] → opportunity.amount
            stage_queries: ["status", "stage", "pipeline", "active"] → opportunity.stage
            active_status: ["active", "open", "qualified", "qualifying", "proposing", "negotiation"] → opportunity.stage (not "closed")
            closed_won: "ClosedWon"
            closed_lost: "ClosedLost"
            
          number_formats:
            - "$50k" = 50000 (k = thousands)
            - "$10K" = 10000 (case insensitive)  
            - "$1.5k" = 1500 (decimals supported)
            - "$1,000" = 1000 (commas ignored)
            - "over $50k" → {"field": "amount", "op": ">", "value": 50000}

          pattern_detection:
            breakdown: "by [field]" → GROUP BY + COUNT
            sum_query: ["worth", "total amount", "value", "sum of"] → SUM aggregation
            filter: "where/with/at [condition]" → WHERE clause
            time_series: "per [time]" → GROUP BY time_period
            metric: "[function] of [field]" → aggregate function

          query_type_rules:
            - "worth", "value", "total" → query_type: "sum"
            - "by [field]" → query_type: "breakdown" 
            - time keywords → query_type: "time_series"
            - filter keywords → query_type: "filtered"
            - multiple patterns → query_type: "complex"

          Return JSON with this enhanced structure:
          {{
            "relevant_objects": [
              {{
                "table_name": "exact_table_name",
                "fields_needed": ["field1", "field2", "created_at"],
                "why_needed": "Brief explanation"
              }}
            ],
            "query_type": "count|sum|breakdown|filtered|time_series|percentage|complex",
            "group_by_fields": ["field1", "field2"],
            "filter_conditions": [
              {{
                "field": "status", 
                "operator": "=|!=|>|<|>=|<=|like|ilike|in|between", 
                "value": "filter_value",
                "reasoning": "why this filter is needed"
              }}
            ],
            "aggregate_function": "count|sum|avg|min|max",
            "time_dimension": "hour|day|week|month|quarter|year",
            "confidence": "high|medium|low",
            "_llm_meta": {{
              "chosen_timeframe": "key_from_time_candidates_or_none",
              "timeframe_reason": "optional_explanation"
            }}
          }}

          TIME RANGE SELECTION (if user didn't specify time):
          AVAILABLE TIME CANDIDATES: {time_candidates}
          
          If user query lacks time specification, choose ONE appropriate timeframe key:
          - Counts/activity queries → "last_30d" 
          - Revenue/financial sums → "this_quarter" or "ytd"
          - Breakdowns by category → "last_30d"
          - Time-series/trend analysis → "last_12mo"
          - Recent activity queries → "last_7d" or "this_month"
          
          If user already specified a time range, use "none" for chosen_timeframe.


          Focus on precision - detect all GROUP BY needs and filter conditions.
        store_as: schema_discovery

      # Phase 3: Get targeted schema context for discovered objects (skip if fast path matched)  
      - action: python
        condition: "not {fast_path_result.matched}"
        code: |
          from core.query_builder.introspection import get_targeted_schema_context
          relevant_objects = schema_discovery.get('relevant_objects', [])
          targeted_schema_text = get_targeted_schema_context(relevant_objects)
          result = {
              'targeted_schema': targeted_schema_text,
              'objects_processed': len(relevant_objects),
              'object_names': [obj.get('table_name', '') for obj in relevant_objects],
              '_metadata': {
                  'phase': 'targeted_schema_context',
                  'generated_at': 'now'
              }
          }
        store_as: targeted_schema_response

      # Phase 4a: Fast Path Query Spec (if pattern matched)
      - action: python
        condition: "{fast_path_result.matched}"
        code: |
          # Log fast path result details with structured logging
          from core.logging.setup import get_logger
          logger = get_logger('ai.data_analytics')
          logger.debug(f"Using fast path result for step 4a", extra={
              'step': '4a', 'matched': fast_path_result.get('matched'),
              'spec_available': fast_path_result.get('spec') is not None,
              'fast_path_result_keys': list(fast_path_result.keys()) if isinstance(fast_path_result, dict) else 'not_dict'
          })
          
          # Use the fast path generated spec directly
          if fast_path_result.get('spec') is None:
            raise ValueError(f"Fast path spec is None! fast_path_result = {fast_path_result}")
          result = fast_path_result['spec']
        store_as: query_specification

      # Phase 4b: Enhanced Query Specification with Intent Awareness (skip if fast path matched)
      - action: ai_generate
        condition: "not {fast_path_result.matched}"
        context:
          user_query: "{input.query}"
          date_today: "{%python_expr%}from datetime import datetime; datetime.now().strftime('%Y-%m-%d'){%/python_expr%}"
          targeted_schema: "{targeted_schema_response.targeted_schema}"
          query_type: "{schema_discovery.query_type}"
          group_by_fields: "{schema_discovery.group_by_fields}"
          filter_conditions: "{schema_discovery.filter_conditions}"
          aggregate_function: "{schema_discovery.aggregate_function}"
          chart_type_hint: "{schema_discovery.chart_type_hint}"
          chosen_timeframe: "{schema_discovery._llm_meta.chosen_timeframe}"
          time_candidates: "{time_candidates.candidates}"
        model: "gpt-4o"  # Deep reasoning for complex spec generation - accuracy over speed
        timeout: 45  # 45 second timeout for complex reasoning
        temperature: 0.1
        max_tokens: 1200
        system_prompt: |
          role: DATABASE_QUERY_GENERATOR  
          domain: ["crm_analytics", "business_intelligence"]
          intent: "Transform natural language analytics queries into structured database specifications"
          
          input_context:
            user_query: "{user_query}"
            schema_context: "{targeted_schema}"
            query_intent: "{query_type}"
            detected_grouping: "{group_by_fields}"
            detected_filters: "{filter_conditions}"
            timeframe_context: "{chosen_timeframe}"
          
          object_mappings:
            deals: ["deals", "deal", "opportunities", "opportunity", "pipeline", "sales"] → "opportunity"
            people: ["contacts", "contact", "leads", "prospects", "people", "users"] → "contact"  
            companies: ["accounts", "account", "companies", "clients", "customers"] → "account"
          
          field_mappings:
            opportunity:
              status_terms: ["active", "open", "status"] → "stage" field
              active_filter: "active opportunities" → stage NOT IN ("ClosedWon", "ClosedLost")
              revenue_terms: ["amount", "value", "worth", "revenue"] → "amount" field
          
          number_formats:
            currency: "$50k" → 50000, "$1.5k" → 1500, "$1,000" → 1000
            operators: "over $X" → {{"field": "amount", "op": ">", "value": X}}
            
          query_patterns:
            count_queries: 
              triggers: ["how many", "count", "number of"]
              output: {{"aggregate": {{"fn": "count", "field": "*"}}}}
              
            sum_queries:
              triggers: ["worth", "total amount", "value", "revenue", "sum"]
              output: {{"aggregate": {{"fn": "sum", "field": "amount"}}}}
              
            breakdown_queries:
              triggers: ["by [field]", "breakdown", "split by"]  
              output: {{"group_by": ["detected_field"], "aggregate": {{"fn": "count", "field": "*"}}}}
              
            filtered_queries:
              triggers: ["where", "with", "over", "under", "active", "closed"]
              output: {{"filters": [detected_conditions]}}
          
          time_handling:
            relative_dates:
              "last month" → use_full_previous_calendar_month
              "this quarter" → use_current_quarter_start_to_now  
              "last 30 days" → use_30_day_rolling_window
            date_format: "YYYY-MM-DDTHH:MM:SS" for between operators
            between_syntax: "start_date,end_date" (comma-separated string)
          
          output_specification:
            format: valid_json_only
            required_fields: ["object"]
            structure: |
              {{
                "object": "opportunity|contact|account",
                "filters": [{{"field": "amount", "op": ">|<|=|!=|between", "value": numeric_or_string}}],
                "aggregate": {{"fn": "count|sum|avg|min|max", "field": "*|amount|specific_field"}},
                "group_by": ["field_name"], 
                "order_by": [{{"field": "field_name", "direction": "asc|desc"}}],
                "limit": 50,
                "_llm_meta": {{"chosen_timeframe": "timeframe_key_or_none"}}
              }}
          
          validation_rules:
            - use_exact_table_names_from_schema
            - convert_currency_strings_to_numbers  
            - include_group_by_for_breakdown_queries
            - add_appropriate_limits_for_performance
            - validate_operators_against_field_types
          
          examples:
            input: "opportunities over $50k"
            output: {{"object": "opportunity", "filters": [{{"field": "amount", "op": ">", "value": 50000}}], "aggregate": {{"fn": "count", "field": "*"}}}}
            
            input: "active opportunities over $10k"
            output: {{"object": "opportunity", "filters": [{{"field": "amount", "op": ">", "value": 10000}}, {{"field": "stage", "op": "not in", "value": ["ClosedWon", "ClosedLost"]}}], "aggregate": {{"fn": "count", "field": "*"}}}}
            
            input: "what are my deals worth in total" 
            output: {{"object": "opportunity", "aggregate": {{"fn": "sum", "field": "amount"}}}}
            
            input: "contacts by industry"
            output: {{"object": "contact", "group_by": ["industry"], "aggregate": {{"fn": "count", "field": "*"}}, "limit": 50}}
            
            input: "closed won opportunities this quarter"
            output: {{"object": "opportunity", "filters": [{{"field": "stage", "op": "=", "value": "ClosedWon"}}], "aggregate": {{"fn": "count", "field": "*"}}, "_llm_meta": {{"chosen_timeframe": "this_quarter"}}}}
          
          constraints:
            - output_only_valid_json
            - no_explanatory_text
            - use_schema_field_names_exactly
            - handle_all_common_analytics_patterns
        context:
          user_query: "{input.query}"
          date_today: "{%python_expr%}from datetime import datetime; datetime.now().strftime('%Y-%m-%d'){%/python_expr%}"
          targeted_schema: "{targeted_schema_response.targeted_schema}"
        store_as: query_specification
        
      # Phase 4.5: Query Validator & Auto-Repair
      - action: python
        code: |
          from core.query_builder.validator import validate_query_spec
          
          # Get the AI-generated spec and context for validation
          raw_spec = query_specification
          
          # Handle both fast path and regular AI pipeline cases
          if fast_path_result.get('matched', False):
              # Fast path case - extract context from fast path metadata
              fast_meta = fast_path_result.get('spec', {}).get('_llm_meta', {})
              validation_context = {
                  'query_type': 'count',  # Fast path is always count-based
                  'group_by_fields': [],
                  'filter_conditions': [],
                  'chart_type_hint': 'metric',  # Fast path results are always metrics
                  'original_query': input.query,
                  'confidence': 'high',  # Fast path has high confidence
                  'fast_path': True,
                  'pattern_type': fast_path_result.get('pattern_type', 'unknown'),
                  'time_candidates': time_candidates  # Include time candidates for validation
              }
          else:
              # Regular AI pipeline case - use schema_discovery
              validation_context = {
                  'query_type': schema_discovery.get('query_type', ''),
                  'group_by_fields': schema_discovery.get('group_by_fields', []),
                  'filter_conditions': schema_discovery.get('filter_conditions', []),
                  'chart_type_hint': schema_discovery.get('chart_type_hint', 'metric'),
                  'original_query': input.query,
                  'confidence': schema_discovery.get('confidence', 'medium'),
                  'fast_path': False,
                  'time_candidates': time_candidates  # Include time candidates for validation
              }
          
          # Validate and normalize the query specification
          validation_result = validate_query_spec(raw_spec, validation_context)
          
          if validation_result.get('validation_success', False):
              # Use the validated spec
              result = validation_result['validated_spec']
              result['_validation_meta'] = {
                  'applied_fixes': validation_result.get('applied_fixes', []),
                  'warnings': validation_result.get('warnings', []),
                  'validator_version': 'v1.0'
              }
          else:
              # Validation failed, use original spec but log errors
              result = raw_spec
              result['_validation_meta'] = {
                  'validation_failed': True,
                  'errors': validation_result.get('errors', []),
                  'needs_llm_repair': validation_result.get('needs_repair', False)
              }
        store_as: validated_query_spec
      
      # Phase 4.5b: LLM Repair (DISABLED - validation working correctly)
      # - action: ai_generate
      #   condition: "{validated_query_spec._validation_meta.needs_llm_repair}"
        context:
          original_spec: "{query_specification}"
          validation_errors: "{validated_query_spec._validation_meta.errors}"
          user_query: "{input.query}"
          schema_context: "{targeted_schema_response.targeted_schema}"
        system_prompt: |
          QUERY SPECIFICATION REPAIR REQUIRED
          
          The original query specification failed validation with these errors:
          {validation_errors}
          
          ORIGINAL SPEC: {original_spec}
          USER QUERY: {user_query}
          SCHEMA CONTEXT: {schema_context}
          
          Please generate a corrected query specification that fixes these validation errors.
          Follow the same JSON format as the original spec but address each validation error.
          
          Common fixes needed:
          - Add missing "group_by" fields for breakdown queries
          - Normalize object names (contacts → contact)
          - Fix invalid operators or field names
          - Add proper date range formats for time filters
          
          Return only the corrected JSON specification.
        store_as: repaired_query_spec
        
      # Use repaired spec if available, otherwise use validated spec
      - action: python
        code: |
          import json
          
          # Choose the best available query specification from previous steps
          repaired_spec = context.get_step_result('repaired_query_spec')
          validated_spec = context.get_step_result('validated_query_spec')
          
          if repaired_spec:
              # Extract the actual query spec from AI response (may be wrapped in 'result' field)
              if isinstance(repaired_spec, dict) and 'result' in repaired_spec:
                  # AI wrapped the spec in a result field, extract it
                  result_content = repaired_spec['result']
                  if isinstance(result_content, str):
                      # Parse JSON string
                      final_spec = json.loads(result_content)
                  else:
                      final_spec = result_content
              else:
                  final_spec = repaired_spec.copy() if isinstance(repaired_spec, dict) else repaired_spec
              
              if isinstance(final_spec, dict):
                  final_spec['_repair_applied'] = True
          elif validated_spec:
              final_spec = validated_spec
          else:
              raise ValueError("No query specification available - both validation and repair failed")
              
          result = final_spec
        store_as: final_query_spec
        
      # Phase 5: Execute the safe database query
      - action: safe_database_query
        query_spec: "{final_query_spec}"
        store_as: raw_data
        
      # Phase 6: Complete LLM Formatter - Full data, complete response
      - action: ai_generate
        model: "gpt-4o-mini"  # Data summarization & formatting - mini is perfect
        temperature: 0.2
        max_tokens: 800
        context:
          original_query: "{input.query}"
          raw_data: "{raw_data}"
          query_spec: "{final_query_spec}"
          conversation_history: "[]"
        system_prompt: |
          You are a data analytics formatter. Build the complete response for the DataAnalytics.tsx frontend component.

          USER QUERY: {original_query}
          RAW DATABASE RESULTS: {raw_data}
          QUERY SPECIFICATION: {query_spec}
          CONVERSATION HISTORY: {conversation_history}

          CRITICAL RULES:
          1. Use ONLY the numbers from RAW DATABASE RESULTS above
          2. Do NOT make up any numbers or use examples
          3. Build chart_data from the actual database records
          4. Choose chart_type based on the actual data structure

          CHART TYPE SELECTION:
          - Single number → "metric"
          - 2-8 categories → "bar_chart"
          - 8+ categories → "table"  
          - Time series (dates) → "line_chart"
          - Part-of-whole analysis → "pie_chart"

          DATA TRANSFORMATION EXAMPLES:
          If raw_data is: [{"created_at_date": "2025-08-01", "count": 3}, {"created_at_date": "2025-08-02", "count": 7}]
          Then chart_data should be: [{"label": "2025-08-01", "value": 3, "percentage": 30.0}, {"label": "2025-08-02", "value": 7, "percentage": 70.0}]

          If raw_data is: 42 (single number)
          Then chart_data should be: [{"label": "Total", "value": 42, "percentage": 100.0}]

          Return complete response ready for frontend:
          {{
            "chart_type": "metric|bar_chart|pie_chart|line_chart|table",
            "value": actual_primary_value,
            "label": "descriptive_label",
            "summary": "Natural language summary using actual numbers",
            "chart_data": [
              {{"label": "category_name", "value": actual_value, "percentage": calculated_percentage}}
            ],
            "total_count": sum_of_all_values
          }}

          FORBIDDEN: Do not use placeholder numbers. Only use actual values from raw_data.
        store_as: formatted_result
        
      # Phase 7: Return final answer with rich analytics response
      - action: return_final_answer
        answer: "{formatted_result.summary}"
        response_type: "analytics"
        layout_hint: "{formatted_result.chart_type}"
        response_data: "{formatted_result}"

# Simple input schema
input_schema:
  type: object
  properties:
    query:
      type: string
      description: "Natural language analytics question"
      examples: 
        - "how many contacts created last month?"
        - "opportunities by stage"
        - "count active accounts"
      minLength: 3
  required: ["query"]

# Rich output schema with visualization info
output_schema:
  type: object
  properties:
    success:
      type: boolean
      description: "Whether the query executed successfully"
    summary:
      type: string
      description: "Human-readable summary of results"
    chart_type:
      type: string
      description: "Recommended visualization type"
      enum: ["metric", "bar_chart", "pie_chart", "line_chart", "table"]
    value:
      type: number
      description: "Primary numeric result (for metrics)"
    label:
      type: string
      description: "Label for the primary result"
    chart_data:
      type: array
      description: "Data points for visualization"
      items:
        type: object
        properties:
          label:
            type: string
          value:
            type: number
          percentage:
            type: number
    columns:
      type: array
      description: "Column definitions for table view"
      items:
        type: object
    raw_count:
      type: number
      description: "Total number of records found"
    query_info:
      type: object
      description: "Debug info about the executed query"
      properties:
        endpoint:
          type: string
        filters_applied:
          type: array
        object_type:
          type: string
    insights:
      type: string
      description: "Key insights or patterns observed in the data"
    llm_feedback:
      type: string
      description: "Explanation for the LLM about the results"
  required: ["success", "summary", "chart_type"]

# No approval needed - read-only analytics
requires_approval: false
permissions: ["objects:read", "reports:execute"]